{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with unbalanced datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bkowshik/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_percentage(subset, total):\n",
    "    return round(100.0 * subset / total, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>user</th>\n",
       "      <th>editor</th>\n",
       "      <th>Powerfull Editor</th>\n",
       "      <th>comment</th>\n",
       "      <th>source</th>\n",
       "      <th>imagery used</th>\n",
       "      <th>date</th>\n",
       "      <th>reasons</th>\n",
       "      <th>reasons__name</th>\n",
       "      <th>create</th>\n",
       "      <th>modify</th>\n",
       "      <th>delete</th>\n",
       "      <th>bbox</th>\n",
       "      <th>is suspect</th>\n",
       "      <th>harmful</th>\n",
       "      <th>checked</th>\n",
       "      <th>check_user__username</th>\n",
       "      <th>check date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47491144</td>\n",
       "      <td>RichRico</td>\n",
       "      <td>JOSM/1.5 (11639 en)</td>\n",
       "      <td>True</td>\n",
       "      <td>Adding junction nodes or bridges to overlappin...</td>\n",
       "      <td>Bing</td>\n",
       "      <td>Not reported</td>\n",
       "      <td>2017-04-05T22:46:26+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SRID=4326;POLYGON ((-46.8202964 -23.693203, -4...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>calfarome</td>\n",
       "      <td>2017-04-05T23:30:53.776282+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47490912</td>\n",
       "      <td>Birgitta_fi</td>\n",
       "      <td>rosemary v0.4.4</td>\n",
       "      <td>False</td>\n",
       "      <td>Modified via wheelmap.org</td>\n",
       "      <td>Not reported</td>\n",
       "      <td>Not reported</td>\n",
       "      <td>2017-04-05T22:27:45+00:00</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Major name modification</td>\n",
       "      <td>5.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SRID=4326;POLYGON ((24.9182827 60.1779368, 24....</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>yurasi</td>\n",
       "      <td>2017-04-05T23:33:08.813791+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID         user               editor Powerfull Editor  \\\n",
       "0  47491144     RichRico  JOSM/1.5 (11639 en)             True   \n",
       "1  47490912  Birgitta_fi      rosemary v0.4.4            False   \n",
       "\n",
       "                                             comment        source  \\\n",
       "0  Adding junction nodes or bridges to overlappin...          Bing   \n",
       "1                          Modified via wheelmap.org  Not reported   \n",
       "\n",
       "   imagery used                       date  reasons            reasons__name  \\\n",
       "0  Not reported  2017-04-05T22:46:26+00:00      NaN                      NaN   \n",
       "1  Not reported  2017-04-05T22:27:45+00:00     23.0  Major name modification   \n",
       "\n",
       "   create  modify  delete                                               bbox  \\\n",
       "0     0.0     1.0     0.0  SRID=4326;POLYGON ((-46.8202964 -23.693203, -4...   \n",
       "1     5.0    41.0     0.0  SRID=4326;POLYGON ((24.9182827 60.1779368, 24....   \n",
       "\n",
       "  is suspect harmful checked check_user__username  \\\n",
       "0      False   False    True            calfarome   \n",
       "1      False    True    True               yurasi   \n",
       "\n",
       "                         check date  \n",
       "0  2017-04-05T23:30:53.776282+00:00  \n",
       "1  2017-04-05T23:33:08.813791+00:00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changesets = pd.read_csv('../data/unbalanced-datasets/changesets.csv')\n",
    "changesets = changesets.drop_duplicates('ID')\n",
    "changesets.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of good changesets: 53556\n",
      "Number of harmful changesets: 5691\n"
     ]
    }
   ],
   "source": [
    "good_changesets = changesets[changesets['harmful'] == False]\n",
    "print('Number of good changesets: {}'.format(good_changesets.shape[0]))\n",
    "\n",
    "harmful_changesets = changesets[changesets['harmful'] == True]\n",
    "print('Number of harmful changesets: {}'.format(harmful_changesets.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(changesets):\n",
    "    \"\"\"Extract required features for training the model.\"\"\"\n",
    "    columns = ['create', 'modify', 'delete', 'harmful']\n",
    "    features = changesets[columns]\n",
    "    return features.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare all features and actual labels for testing all models.\n",
    "all_features = get_features(changesets)\n",
    "all_X = all_features.drop('harmful', axis=1)\n",
    "all_y = all_features['harmful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_scaler(features):    \n",
    "    \"\"\"Scale features using RobustScaler which is suitable for data with outliers.\"\"\"\n",
    "    X = features.drop('harmful', axis=1)\n",
    "    return preprocessing.RobustScaler().fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(X, y):\n",
    "    \"\"\"Return a trained model.\"\"\"\n",
    "    model = SVC(kernel='rbf')\n",
    "    model.fit(X, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_performance(y_true, y_pred):\n",
    "    print(classification_report(y_true, y_pred, labels=[True, False], target_names=['problematic', 'not problematic']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Using all changesets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    problematic       0.98      0.03      0.06      5684\n",
      "not problematic       0.91      1.00      0.95     53455\n",
      "\n",
      "    avg / total       0.91      0.91      0.87     59139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = get_features(changesets)\n",
    "scaler = get_scaler(features)\n",
    "\n",
    "X = features.drop('harmful', axis=1)\n",
    "y = features['harmful']\n",
    "\n",
    "model = get_model(scaler.transform(X), y)\n",
    "y_model = model.predict(scaler.transform(all_X))\n",
    "\n",
    "print_performance(all_y, y_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Undersample good changesets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11382, 19)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undersampled_good_changesets = good_changesets.sample(harmful_changesets.shape[0])\n",
    "undersampled_changesets = pd.concat([undersampled_good_changesets, harmful_changesets])\n",
    "undersampled_changesets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    problematic       0.18      0.83      0.30      5684\n",
      "not problematic       0.97      0.60      0.74     53455\n",
      "\n",
      "    avg / total       0.90      0.62      0.70     59139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = get_features(undersampled_changesets)\n",
    "scaler = get_scaler(features)\n",
    "\n",
    "X = features.drop('harmful', axis=1)\n",
    "y = features['harmful']\n",
    "\n",
    "model = get_model(scaler.transform(X), y)\n",
    "y_model = model.predict(scaler.transform(all_X))\n",
    "\n",
    "print_performance(all_y, y_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Undersample good changesets by 4x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28455, 19)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undersampled_good_changesets = good_changesets.sample(harmful_changesets.shape[0] * 4)\n",
    "undersampled_changesets = pd.concat([undersampled_good_changesets, harmful_changesets])\n",
    "undersampled_changesets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    problematic       0.86      0.05      0.10      5684\n",
      "not problematic       0.91      1.00      0.95     53455\n",
      "\n",
      "    avg / total       0.90      0.91      0.87     59139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = get_features(undersampled_changesets)\n",
    "scaler = get_scaler(features)\n",
    "\n",
    "X = features.drop('harmful', axis=1)\n",
    "y = features['harmful']\n",
    "\n",
    "model = get_model(scaler.transform(X), y)\n",
    "y_model = model.predict(scaler.transform(all_X))\n",
    "\n",
    "print_performance(all_y, y_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4: Oversample harmful changesets by 4x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76320, 19)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Oversampling harmful changesets by 4 times\n",
    "overampled_harmful_changesets = pd.concat([harmful_changesets] * 4)\n",
    "overampled_changesets = pd.concat([good_changesets, overampled_harmful_changesets])\n",
    "overampled_changesets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    problematic       0.74      0.09      0.15      5684\n",
      "not problematic       0.91      1.00      0.95     53455\n",
      "\n",
      "    avg / total       0.89      0.91      0.88     59139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = get_features(overampled_changesets)\n",
    "scaler = get_scaler(features)\n",
    "\n",
    "X = features.drop('harmful', axis=1)\n",
    "y = features['harmful']\n",
    "\n",
    "model = get_model(scaler.transform(X), y)\n",
    "y_model = model.predict(scaler.transform(all_X))\n",
    "\n",
    "print_performance(all_y, y_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 5: Let's try Decision Trees\n",
    "> Decision trees often perform well on imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    problematic       0.06      0.01      0.01      5684\n",
      "not problematic       0.90      0.99      0.94     53455\n",
      "\n",
      "    avg / total       0.82      0.89      0.85     59139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = get_features(changesets)\n",
    "scaler = get_scaler(features)\n",
    "\n",
    "X = features.drop('harmful', axis=1)\n",
    "y = features['harmful']\n",
    "\n",
    "# Training a decision tree.\n",
    "from sklearn import tree\n",
    "model = tree.DecisionTreeClassifier()\n",
    "model = model.fit(X, y)\n",
    "\n",
    "# Get predictions from decision tree model.\n",
    "y_model = model.predict(scaler.transform(all_X))\n",
    "\n",
    "print_performance(all_y, y_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 6: Set class_weight='balanced'\n",
    "\n",
    "> In SVC, if data for classification are unbalanced (e.g. many positive and few negative), set class_weight='balanced' and/or try different penalty parameters C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    problematic       0.18      0.81      0.29      5684\n",
      "not problematic       0.97      0.61      0.75     53455\n",
      "\n",
      "    avg / total       0.89      0.63      0.70     59139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = get_features(changesets)\n",
    "scaler = get_scaler(features)\n",
    "\n",
    "X = features.drop('harmful', axis=1)\n",
    "y = features['harmful']\n",
    "\n",
    "model = SVC(kernel='rbf', class_weight='balanced')\n",
    "model.fit(scaler.transform(X), y)\n",
    "y_model = model.predict(scaler.transform(all_X))\n",
    "\n",
    "print_performance(all_y, y_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 7: Try different penalty parameters C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    problematic       0.18      0.81      0.29      5684\n",
      "not problematic       0.97      0.60      0.74     53455\n",
      "\n",
      "    avg / total       0.89      0.62      0.70     59139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = get_features(changesets)\n",
    "scaler = get_scaler(features)\n",
    "\n",
    "X = features.drop('harmful', axis=1)\n",
    "y = features['harmful']\n",
    "\n",
    "# The default penalty is `1`, so trying a penalty of `2`.\n",
    "model = SVC(kernel='rbf', class_weight='balanced', C=2)\n",
    "model.fit(scaler.transform(X), y)\n",
    "y_model = model.predict(scaler.transform(all_X))\n",
    "\n",
    "print_performance(all_y, y_model)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
